<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI Realtime Voice Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 2rem;
            text-align: center;
            max-width: 500px;
            width: 90%;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            margin-bottom: 2rem;
            font-size: 2rem;
            font-weight: 300;
        }
        
        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #ff6b6b, #ee5a24);
            color: white;
            font-size: 2rem;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 1rem auto;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }
        
        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(0, 0, 0, 0.3);
        }
        
        .mic-button.listening {
            background: linear-gradient(135deg, #26de81, #20bf6b);
            animation: pulse 1.5s infinite;
        }
        
        .mic-button.disabled {
            background: #666;
            cursor: not-allowed;
            transform: none;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }
        
        .status {
            margin: 1rem 0;
            padding: 0.5rem;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            font-size: 0.9rem;
        }
        
        .transcript {
            margin: 1rem 0;
            padding: 1rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            min-height: 60px;
            text-align: left;
            font-size: 0.9rem;
            line-height: 1.4;
        }
        
        .transcript h3 {
            margin-bottom: 0.5rem;
            color: #ffd700;
        }
        
        .controls {
            display: flex;
            gap: 1rem;
            justify-content: center;
            margin-top: 1rem;
        }
        
        .btn {
            padding: 0.5rem 1rem;
            border: none;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.2);
            color: white;
            cursor: pointer;
            transition: background 0.3s ease;
        }
        
        .btn:hover {
            background: rgba(255, 255, 255, 0.3);
        }
        
        .btn:disabled {
            background: rgba(255, 255, 255, 0.1);
            cursor: not-allowed;
        }
        
        .volume-indicator {
            width: 100%;
            height: 4px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 2px;
            margin: 1rem 0;
            overflow: hidden;
        }
        
        .volume-bar {
            height: 100%;
            background: linear-gradient(90deg, #26de81, #ffd700, #ff6b6b);
            width: 0%;
            transition: width 0.1s ease;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ Voice Assistant</h1>
        
        <button id="micButton" class="mic-button disabled">
            <span id="micIcon">ðŸŽ¤</span>
        </button>
        
        <div id="status" class="status">Connecting...</div>
        
        <div class="volume-indicator">
            <div id="volumeBar" class="volume-bar"></div>
        </div>
        
        <div id="transcript" class="transcript">
            <h3>Conversation</h3>
            <div id="transcriptContent">Click the microphone to start talking...</div>
        </div>
        
        <div class="controls">
            <button id="connectBtn" class="btn">Connect</button>
            <button id="clearBtn" class="btn" disabled>Clear</button>
        </div>
    </div>

    <script>
        class RealtimeVoiceAssistant {
            constructor() {
                this.ws = null;
                this.mediaRecorder = null;
                this.audioContext = null;
                this.analyser = null;
                this.isConnected = false;
                this.isListening = false;
                this.transcriptContent = [];
                
                this.micButton = document.getElementById('micButton');
                this.micIcon = document.getElementById('micIcon');
                this.status = document.getElementById('status');
                this.transcriptDiv = document.getElementById('transcriptContent');
                this.connectBtn = document.getElementById('connectBtn');
                this.clearBtn = document.getElementById('clearBtn');
                this.volumeBar = document.getElementById('volumeBar');
                
                this.initializeEventListeners();
            }
            
            initializeEventListeners() {
                this.micButton.addEventListener('click', () => this.toggleListening());
                this.connectBtn.addEventListener('click', () => this.connect());
                this.clearBtn.addEventListener('click', () => this.clearTranscript());
            }
            
            connect() {
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${protocol}//${window.location.host}`;
                
                this.ws = new WebSocket(wsUrl);
                
                this.ws.onopen = () => {
                    console.log('Connected to server');
                    this.updateStatus('Connected to server. Initializing...');
                    this.ws.send(JSON.stringify({ type: 'connect' }));
                };
                
                this.ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    this.handleServerMessage(data);
                };
                
                this.ws.onclose = () => {
                    console.log('Disconnected from server');
                    this.updateStatus('Disconnected');
                    this.isConnected = false;
                    this.micButton.classList.add('disabled');
                    this.connectBtn.disabled = false;
                };
                
                this.ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    this.updateStatus('Connection error');
                };
            }
            
            handleServerMessage(data) {
                switch (data.type) {
                    case 'connected':
                        this.isConnected = true;
                        this.updateStatus('Ready! Click the microphone to start.');
                        this.micButton.classList.remove('disabled');
                        this.clearBtn.disabled = false;
                        this.connectBtn.disabled = true;
                        break;
                        
                    case 'conversation.item.input_audio_transcription.completed':
                        if (data.transcript) {
                            this.addToTranscript('You', data.transcript);
                        }
                        break;
                        
                    case 'response.audio_transcript.delta':
                        this.updateAssistantResponse(data.delta);
                        break;
                        
                    case 'response.audio_transcript.done':
                        this.finalizeAssistantResponse(data.transcript);
                        break;
                        
                    case 'response.audio.delta':
                        if (data.delta) {
                            this.playAudioDelta(data.delta);
                        }
                        break;
                        
                    case 'input_audio_buffer.speech_started':
                        this.updateStatus('Listening... (speech detected)');
                        break;
                        
                    case 'input_audio_buffer.speech_stopped':
                        this.updateStatus('Processing...');
                        break;
                        
                    case 'error':
                        console.error('Server error:', data.message);
                        this.updateStatus(`Error: ${data.message}`);
                        break;
                        
                    case 'disconnected':
                        this.updateStatus('OpenAI connection lost');
                        this.isConnected = false;
                        break;
                }
            }
            
            async toggleListening() {
                if (!this.isConnected) return;
                
                if (this.isListening) {
                    this.stopListening();
                } else {
                    await this.startListening();
                }
            }
            
            async startListening() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 24000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    this.audioContext = new AudioContext({ sampleRate: 24000 });
                    this.analyser = this.audioContext.createAnalyser();
                    this.analyser.fftSize = 256;
                    
                    const source = this.audioContext.createMediaStreamSource(stream);
                    source.connect(this.analyser);
                    
                    this.setupVolumeIndicator();
                    
                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    
                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0 && this.ws.readyState === WebSocket.OPEN) {
                            this.convertAndSendAudio(event.data);
                        }
                    };
                    
                    this.mediaRecorder.start(100); // Send audio in 100ms chunks
                    
                    this.isListening = true;
                    this.micButton.classList.add('listening');
                    this.micIcon.textContent = 'ðŸ”´';
                    this.updateStatus('Listening... Speak now!');
                    
                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    this.updateStatus('Microphone access denied');
                }
            }
            
            stopListening() {
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    this.mediaRecorder.stop();
                    this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                }
                
                if (this.audioContext) {
                    this.audioContext.close();
                }
                
                this.isListening = false;
                this.micButton.classList.remove('listening');
                this.micIcon.textContent = 'ðŸŽ¤';
                this.updateStatus('Stopped listening');
                this.volumeBar.style.width = '0%';
            }
            
            setupVolumeIndicator() {
                const updateVolume = () => {
                    if (!this.analyser || !this.isListening) return;
                    
                    const dataArray = new Uint8Array(this.analyser.frequencyBinCount);
                    this.analyser.getByteFrequencyData(dataArray);
                    
                    const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                    const percentage = (average / 255) * 100;
                    
                    this.volumeBar.style.width = `${percentage}%`;
                    
                    if (this.isListening) {
                        requestAnimationFrame(updateVolume);
                    }
                };
                
                updateVolume();
            }
            
            async convertAndSendAudio(blob) {
                const arrayBuffer = await blob.arrayBuffer();
                const audioContext = new AudioContext({ sampleRate: 24000 });
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // Convert to PCM16
                const pcm16 = this.convertToPCM16(audioBuffer);
                const base64Audio = btoa(String.fromCharCode(...new Uint8Array(pcm16)));
                
                if (this.ws.readyState === WebSocket.OPEN) {
                    this.ws.send(JSON.stringify({
                        type: 'input_audio_buffer.append',
                        audio: base64Audio
                    }));
                }
            }
            
            convertToPCM16(audioBuffer) {
                const length = audioBuffer.length;
                const result = new Int16Array(length);
                const channelData = audioBuffer.getChannelData(0);
                
                for (let i = 0; i < length; i++) {
                    const sample = Math.max(-1, Math.min(1, channelData[i]));
                    result[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                }
                
                return result.buffer;
            }
            
            playAudioDelta(deltaBase64) {
                try {
                    const audioData = atob(deltaBase64);
                    const audioArray = new Uint8Array(audioData.length);
                    for (let i = 0; i < audioData.length; i++) {
                        audioArray[i] = audioData.charCodeAt(i);
                    }
                    
                    // Convert PCM16 to AudioBuffer and play
                    const audioContext = new AudioContext();
                    const audioBuffer = audioContext.createBuffer(1, audioArray.length / 2, 24000);
                    const channelData = audioBuffer.getChannelData(0);
                    
                    for (let i = 0; i < channelData.length; i++) {
                        const sample = (audioArray[i * 2] | (audioArray[i * 2 + 1] << 8));
                        channelData[i] = sample < 0x8000 ? sample / 0x8000 : (sample - 0x10000) / 0x8000;
                    }
                    
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    source.start();
                    
                } catch (error) {
                    console.error('Error playing audio:', error);
                }
            }
            
            addToTranscript(speaker, text) {
                this.transcriptContent.push({ speaker, text, timestamp: new Date() });
                this.updateTranscriptDisplay();
            }
            
            updateAssistantResponse(delta) {
                if (this.transcriptContent.length > 0) {
                    const lastItem = this.transcriptContent[this.transcriptContent.length - 1];
                    if (lastItem.speaker === 'Assistant' && !lastItem.final) {
                        lastItem.text += delta;
                    } else {
                        this.transcriptContent.push({ 
                            speaker: 'Assistant', 
                            text: delta, 
                            timestamp: new Date(),
                            final: false 
                        });
                    }
                } else {
                    this.transcriptContent.push({ 
                        speaker: 'Assistant', 
                        text: delta, 
                        timestamp: new Date(),
                        final: false 
                    });
                }
                this.updateTranscriptDisplay();
            }
            
            finalizeAssistantResponse(fullText) {
                if (this.transcriptContent.length > 0) {
                    const lastItem = this.transcriptContent[this.transcriptContent.length - 1];
                    if (lastItem.speaker === 'Assistant') {
                        lastItem.text = fullText;
                        lastItem.final = true;
                    }
                }
                this.updateTranscriptDisplay();
            }
            
            updateTranscriptDisplay() {
                const content = this.transcriptContent.map(item => {
                    const time = item.timestamp.toLocaleTimeString();
                    return `<div style="margin-bottom: 10px;">
                        <strong style="color: ${item.speaker === 'You' ? '#ffd700' : '#26de81'};">
                            ${item.speaker} (${time}):
                        </strong><br>
                        ${item.text}
                    </div>`;
                }).join('');
                
                this.transcriptDiv.innerHTML = content || 'Click the microphone to start talking...';
                this.transcriptDiv.scrollTop = this.transcriptDiv.scrollHeight;
            }
            
            clearTranscript() {
                this.transcriptContent = [];
                this.updateTranscriptDisplay();
            }
            
            updateStatus(message) {
                this.status.textContent = message;
            }
        }
        
        // Initialize the voice assistant when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new RealtimeVoiceAssistant();
        });
    </script>
</body>
</html>
